NUMA(Non Uniform Memory Access Achitecture 非一致访问分布共享存储技术)

说明：转自百度百科 http://baike.baidu.com/view/380118.htm 
以及 Wikipedia

    NUMA 技术可以使众多服务器像单一系统那样运转，同时保留小系统便于编程和管理的优点。基于电子商务应用对内存访问提出的更高的要求，NUMA也向复杂的结构设计提出了挑战。


############# Section Overview : 三种体系模型 SMP, MPP, NUMA ###################

　　我们知道，当今数据计算领域的主要应用程序和模型可大致分为联机事务处理（OLTP）、决策支持系统（DSS）和企业信息通讯（BusinessCommunications）三大类。而小型独立服务器模式、SMP（对称多处理）模式、MPP（大规模并行处理）模式和NUMA模式，则是上述3类系统设计人员在计算平台的体系结构方面可以采用的选择。
　　为了全面的了解NUMA的优势，我们不妨先来考察一下这几种模式在处理器与存储器结构方面的区别。
　　SMP模式将多个处理器与一个集中的存储器相连。在SMP模式下，所有处理器都可以访问同一个系统物理存储器，这就意味着SMP系统只运行操作系统的一个拷贝。因此SMP系统有时也被称为一致存储器访问（UMA）结构体系，一致性意指无论在什么时候，处理器只能为内存的每个数据保持或共享唯一一个数值。很显然，SMP的缺点是可伸缩性有限，因为在存储器接口达到饱和的时候，增加处理器并不能获得更高的性能。
　　MPP模式则是一种分布式存储器模式，能够将更多的处理器纳入一个系统的存储器。一个分布式存储器模式具有多个节点，每个节点都有自己的存储器，可以配置为SMP模式，也可以配置为非SMP模式。单个的节点相互连接起来就形成了一个总系统。MPP体系结构对硬件开发商颇具吸引力，因为它们出现的问题比较容易解决，开发成本比较低。由于没有硬件支持共享内存或高速缓存一致性的问题，所以比较容易实现大量处理器的连接。
　　可见，单一SMP模式与MPP模式的关键区别在于，在SMP模式中，数据一致性是由硬件专门管理的，这样做比较容易实现，但成本较高；在MPP模式中，节点之间的一致性是由软件来管理，因此，它的速度相对较慢，但成本却低得多。
　　在美国某大学的研究项目中被提出来的NUMA模式，也采用了分布式存储器模式，不同的是所有节点中的处理器都可以访问全部的系统物理存储器。然而，每个处理器访问本节点内的存储器所需要的时间，可能比访问某些远程节点内的存储器所花的时间要少得多。换句话说，也就是访问存储器的时间是不一致的，这也就是这种模式之所以被称为“NUMA”的原因。简而言之，NUMA既保持了SMP模式单一操作系统拷贝、简便的应用程序编程模式以及易于管理的特点，又继承了MPP模式的可扩充性，可以有效地扩充系统的规模。这也正是NUMA的优势所在。

############# Section Basic Concept : What is NUMA? ############################

    Non-Uniform Memory Access (NUMA) is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to a processor. Under NUMA, a processor can access its own local memory faster than non-local memory, that is, memory local to another processor or memory shared between processors.

    NUMA architectures logically follow in scaling from symmetric multiprocessing (SMP) architectures. Their commercial development came in work by Burroughs (later Unisys), Convex Computer (later Hewlett-Packard), Honeywell Information Systems Italy (HISI) (later Groupe Bull), Silicon Graphics (later Silicon Graphics International), Sequent Computer Systems (later IBM), Data General (later EMC) and Digital (later Compaq, now HP) during the 1990s. Techniques developed by these companies later featured in a variety of Unix-like operating systems, and somewhat in Windows NT.

    The first commercial implementation of a NUMA-based Unix system was the Symmetrical Multi Processing XPS-100 family of servers, designed by Dan Gielan of VAST Corporation for Honeywell Information Systems Italy. The tremendous success of the architecture propelled HISI to the #1 spot of Unix vendors in Europe.

*不靠谱的翻译部分：
    非一致内存访问是一种在多处理器情况下计算机内存的设计，这种方式对于处理器而言，访问内存的时间依赖于内存的位置。在NUMA中，一个处理器访问它自己的本地内存比访问非本地内存（属于另一个处理器的内存或者多个处理器的共享内存）要快。

    省略，这一段很商业。

    Modern CPUs operate considerably faster than the main memory they use. In the early days of computing and data processing the CPU generally ran slower than its memory. The performance lines crossed in the 1960s with the advent of the first supercomputers and of high-speed computing. Since then, CPUs, increasingly "starved for data", have had to stall while they wait for memory accesses to complete. Many supercomputer designs of the 1980s and 90s focused on providing high-speed memory access as opposed to faster processors, allowing them to work on large data-sets at speeds other systems could not approach.

    Limiting the number of memory accesses provided the key to extracting high performance from a modern computer. For commodity processors, this means installing an ever-increasing amount of high-speed cache memory and using increasingly sophisticated algorithms to avoid "cache misses". But the dramatic increase in size of the operating systems and of the applications run on them has generally overwhelmed these cache-processing improvements. Multi-processor systems make the problem considerably worse. Now a system can starve several processors at the same time, notably because only one processor can access memory at a time.

    NUMA attempts to address this problem by providing separate memory for each processor, avoiding the performance hit when several processors attempt to address the same memory. For problems involving spread data (common for servers and similar applications), NUMA can improve the performance over a single shared memory by a factor of roughly the number of processors (or separate memory banks).

    Of course, not all data ends up confined to a single task, which means that more than one processor may require the same data. To handle these cases, NUMA systems include additional hardware or software to move data between banks. This operation slows the processors attached to those banks, so the overall speed increase due to NUMA depends heavily on the exact nature of the running tasks.

*以下部分是本人很不靠谱的翻译：

    现代CPU的处理速度要比他们使用的主内存快很多，而在早些时候CPU计算和数据处理数度比它所使用的内存会很多。伴随着1960年代第一台超级计算机和高速计算的出现，他们的性能曲线开始出现交叉。从这之后，CPU开始变的越来越缺乏数据数据处理（因为CPU的处理速度变得比内存读写快），开始不得不在内存把数据处理完成之前无事可做。很多1980年代和1990年代设计的计算机开始更加关注高速的内存读写而不是更快的处理器运算速度，以便让他们提供其他系统无法达到的数据处理速度。

    内存读取速度的限制成为了限制计算机速度的关键。对于家用计算机来讲，这个意味着不断增加增加更多的高速缓存并且使用日趋复杂的算法来避免丢失缓存。但是操作系统中更多的更消耗内存的程序最终还是超过了缓存提升。多核系统使得问题变得更糟。现在一个系统同时运行在多个处理器上，而在一个时刻只有一个处理器可以访问内存，这个问题变得更加紧迫。

    NUMA试图通过为每个处理器提供隔离的内存来解决这个问题来避免多个处理器同时访问同一块内存。对于隔离数据这样的问题（对于服务端程序和类似的程序），NUMA可以通过多个处理器来提高系能（这个地方不会翻译）。

    当然，并不是所有的数据都存在与一个单独的任务中，那以为着多个处理器同时需要同一块数据。为了应对这样的情况，NUMA系统包含了附加的硬件或者软件在不同的内存银行中迁移数据。这个操作会减慢处理器连接这些内存单元的速度，但是整体速度跟NUMA高度依赖所运行任务的特性而有不同程度的提高。

    PS:翻译很烂！

###################### Section ： Linux 手册上对NUMA的解释 ###########

DESCRIPTION
       Non-Uniform Memory Access (NUMA) refers to multiprocessor systems whose
       memory is divided into multiple memory nodes.  The  access  time  of  a
       memory  node depends on the relative locations of the accessing CPU and
       the accessed node.  (This contrasts  with  a  symmetric  multiprocessor
       system, where the access time for all of the memory is the same for all
       CPUs.)  Normally, each CPU on a NUMA system has  a  local  memory  node
       whose contents can be accessed faster than the memory in the node local
       to another CPU or the memory on a bus shared by all CPUs.

       NUMA是指多处理器系统中内存被分为多个内存单元。一个内存单元的可访问时间
       依赖于要访问内存的处理器和此内存的相对位置。（这和SMP所有处理器访问访问
       内存的相对时间相同相反。）一般来讲，NUMA上的每一个每一个CPU都有一个本地
       内存单元，CPU访问本地的内存单元要比访问非本地的内存单元和共享的内存要快。

